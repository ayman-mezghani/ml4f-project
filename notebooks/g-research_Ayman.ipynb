{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# G-Research predictions\n",
    "Ekaterina Kryukova, Ayman Mezghani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import math\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.arima_model import ARMA, ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "# https://github.com/philipperemy/keras-tcn\n",
    "#from tcn import TCN\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_path = '/kaggle/input/'\n",
    "data_path = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "info = pd.read_csv(data_path + \"g-research-crypto-forecasting/asset_details.csv\")\n",
    "train = pd.read_csv(data_path + \"g-research-crypto-forecasting/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info.Asset_Name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp\n",
    "train['timestamp'] = pd.to_datetime(train['timestamp'], unit='s')\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candlestick charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary for assets\n",
    "rename_dict = {}\n",
    "asset_details = info \n",
    "for a in asset_details['Asset_ID']:\n",
    "    rename_dict[a] = asset_details[asset_details.Asset_ID == a].Asset_Name.values[0]\n",
    "\n",
    "display(rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supplemental_train['timestamp'] = supplemental_train['timestamp'].astype('datetime64[s]')\n",
    "#example_test['timestamp'] = example_test['timestamp'].astype('datetime64[s]')\n",
    "\n",
    "#train['date'] = pd.DatetimeIndex(train['timestamp']).date\n",
    "#supplemental_train['date'] = pd.DatetimeIndex(supplemental_train['timestamp']).date\n",
    "#example_test['date'] = pd.DatetimeIndex(example_test['timestamp']).date\n",
    "\n",
    "# Resample\n",
    "train_daily = pd.DataFrame()\n",
    "\n",
    "for asset_id in asset_details.Asset_ID:\n",
    "    train_single = train[train.Asset_ID == asset_id].copy()\n",
    "\n",
    "    train_single_new = train_single[['timestamp', 'Count']].resample('D', on='timestamp').sum()\n",
    "    train_single_new['Open'] = train_single[['timestamp', 'Open']].resample('D', on='timestamp').first()['Open']\n",
    "    train_single_new['High'] = train_single[['timestamp', 'High']].resample('D', on='timestamp').max()['High']\n",
    "    train_single_new['Low'] = train_single[['timestamp', 'Low']].resample('D', on='timestamp').min()['Low']\n",
    "    train_single_new['Close'] = train_single[['timestamp', 'Close']].resample('D', on='timestamp').last()['Close']\n",
    "    train_single_new['Volume'] = train_single[['timestamp', 'Volume']].resample('D', on='timestamp').sum()['Volume']\n",
    "    # train_single_new['VWAP']\n",
    "    #train_single_new['Target'] = train_single[['timestamp','Target']].resample('D', on='timestamp').mean()['Target']\n",
    "    train_single_new['Asset_ID'] = asset_id\n",
    "\n",
    "    train_daily = train_daily.append(train_single_new.reset_index(drop=False))\n",
    "    \n",
    "train_daily = train_daily.sort_values(by=['timestamp', 'Asset_ID']).reset_index(drop=True)\n",
    "\n",
    "train_daily = train_daily.pivot(index='timestamp', columns='Asset_ID')[['Count', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "\n",
    "train_daily.reset_index(drop=False, inplace=True)\n",
    "\n",
    "display(train_daily.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize Bitcoin for recent data rows - last 200 rows\n",
    "crypto_df = train\n",
    "\n",
    "crypto_df.index = pd.to_datetime(crypto_df.timestamp, unit='s')\n",
    "btc = crypto_df[crypto_df[\"Asset_ID\"] == 1] # Asset_ID = 1 for Bitcoin\n",
    "btc_mini = btc.iloc[-200:] # Select recent data rows\n",
    "\n",
    "fig = go.Figure(data=[go.Candlestick(x=btc_mini.index, open=btc_mini['Open'], high=btc_mini['High'], low=btc_mini['Low'], close=btc_mini['Close'])])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Distribution among differnet Assets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_count = []\n",
    "for i in range(14):\n",
    "    count = (train[\"Asset_ID\"] == i).sum()\n",
    "    asset_count.append(count)\n",
    "\n",
    "fig = px.bar(x=asset_details.sort_values(\"Asset_ID\")[\"Asset_Name\"],\n",
    "             y=asset_count , \n",
    "             color=asset_count ,\n",
    "             color_continuous_scale=\"Emrld\") \n",
    "\n",
    "fig.update_xaxes(title=\"Assets\")\n",
    "fig.update_yaxes(title=\"Number of Rows\")\n",
    "\n",
    "fig.update_layout(showlegend = True,\n",
    "                  title={'text': 'Data Distribution ',\n",
    "                         'y':0.95,\n",
    "                         'x':0.5,\n",
    "                         'xanchor': 'center',\n",
    "                         'yanchor': 'top'})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data visualtion for 14 popular cryptocurrency\n",
    "2. Price History for selected individual cryptocurrency\n",
    "3. Basic Arima Model for price prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time history of 3 coins and their returns\n",
    "https://www.kaggle.com/fangya/cryptocurrency-data-visualization-arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Missing Time Values\n",
    "def fill_timestamp(asset_id, data=train):\n",
    "    df = train[train[\"Asset_ID\"]==asset_id].copy()\n",
    "    df = df.set_index(\"timestamp\").sort_index()\n",
    "    df = df.reindex(pd.date_range(df.index[0], df.index[-1], freq='min'), method=\"pad\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Bitcoin\n",
    "btc = fill_timestamp(asset_id=1)\n",
    "\n",
    "#  Ethereum\n",
    "eth = fill_timestamp(asset_id=6)\n",
    "\n",
    "#  Cardano\n",
    "ada = fill_timestamp(asset_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cryptocurrency Log Return Correlation Plot for 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Return \n",
    "def log_return(series, periods=1):\n",
    "    return np.log(series).diff(periods=periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc[btc.index.year == 2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all2021 = []\n",
    "for asset_id, asset_name in zip(info.Asset_ID, info.Asset_Name):\n",
    "    asset = fill_timestamp(asset_id, data=train)\n",
    "    \n",
    "    #take the specific timeframe\n",
    "    asset = asset[asset.index.year == 2021]\n",
    "\n",
    "    lret = log_return(asset.Close.fillna(0))[1:]\n",
    "    \n",
    "    lret.rename(asset_name, inplace=True)\n",
    "    \n",
    "    all2021.append(lret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all2021 = pd.concat(all2021, axis=1, keys=[s.name for s in all2021])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the heatmap\n",
    "corr = all2021.corr()\n",
    "fig = sns.heatmap(corr, \n",
    "                  xticklabels=corr.columns,\n",
    "                  yticklabels=corr.columns)\n",
    "\n",
    "fig.get_figure().savefig('corr.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redundant_pairs(df):\n",
    "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "get_top_abs_correlations(all2021, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join two asset in single DataFrame\n",
    "\n",
    "lret_btc_long = log_return(btc.Close)[1:]\n",
    "lret_eth_long = log_return(eth.Close)[1:]\n",
    "lret_btc_long.rename('lret_btc', inplace=True)\n",
    "lret_eth_long.rename('lret_eth', inplace=True)\n",
    "two_assets = pd.concat([lret_btc_long, lret_eth_long], axis=1)\n",
    "\n",
    "# group consecutive rows and use .corr() for correlation between columns\n",
    "corr_time = two_assets.groupby(two_assets.index//(10000*60)).corr().loc[:, \"lret_btc\"].loc[:, \"lret_eth\"]\n",
    "\n",
    "corr_time.plot();\n",
    "plt.xticks([])\n",
    "plt.ylabel(\"Correlation\")\n",
    "plt.title(\"Correlation between BTC and ETH over time\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Correlation plot we can see Bitcoin Cash is highly correlated with EOS.IO.\n",
    "\n",
    "Binance Coin is correlated with many crypto currencies, such as , Bitcoin, Bitcoin Cash, Cardano, Ethereum.\n",
    "\n",
    "We can have a roughly conclude that Binance Coin, Bitcoin Cash prices have a strong relation with other cryptocurrencies. Whereas Dogecoin and Monero prices are quite independent. Ealier we mentioned Monero is based a donation, which makes sense it is not correlated so much with other coins.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corr changes from time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all2021.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Closing Price for BTC, ETH, ADA\n",
    "f = plt.figure(figsize=(10,12))  \n",
    "\n",
    "def gplot(no , data, price, label, ylabel, color):\n",
    "    ax = f.add_subplot(no)\n",
    "    plt.plot(data[price], label=label, color=color)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(ylabel)\n",
    "    return plt\n",
    "\n",
    "gplot(no=311, data=btc, price=\"Close\", label=\"BTC 2021 Overall Performance\", ylabel=\"BTC Closing Price\", color=\"Lightskyblue\")\n",
    "gplot(no=312, data=eth, price=\"Close\", label=\"ETH 2021 Overall Performance\", ylabel=\"ETH Closing Price\", color=\"Coral\")\n",
    "gplot(no=313, data=ada, price=\"Close\", label=\"Cardano 2021 Overall Performance\", ylabel=\"ADA Closing Price\", color=\"khaki\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target : 15 minute resudualized returns\n",
    "#Residual Return: An asset's residual return equals its excess return minus beta times the benchmark excess return.\n",
    "\n",
    "f = plt.figure(figsize=(10,12))  \n",
    "gplot(no=311, data=btc, price=\"Target\", label=\"BTC 2021 15min Return Residue\", ylabel=\"BTC residual return\", color=\"Aqua\")\n",
    "gplot(no=312, data=eth, price=\"Target\", label=\"ETH 2021 15min Return Residue\", ylabel=\"ETH residual return\", color=\"Pink\")\n",
    "gplot(no=313, data=ada, price=\"Target\", label=\"ADA 2021 15min Return Residue\", ylabel=\"ADA residual return\", color=\"gold\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see ETH, and BTC residual return are relatively stable compared to ADA. This might be a good implication that if the investor would take short time trading opportunities, ADA is a better choice.\n",
    "\n",
    "If the investor is risk averse, BTC or ETH will be a better fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#candlestick\n",
    "def c_chart(data,label):\n",
    "    candlestick = go.Figure(data = [go.Candlestick(x =data.index, \n",
    "                                               open = data[('Open')], \n",
    "                                               high = data[('High')], \n",
    "                                               low = data[('Low')], \n",
    "                                               close = data[('Close')])])\n",
    "    candlestick.update_xaxes(title_text = 'Time',\n",
    "                             rangeslider_visible = True)\n",
    "\n",
    "    candlestick.update_layout(\n",
    "    title = {\n",
    "        'text': '{:} Candelstick Chart'.format(label),\n",
    "        \"y\":0.8,\n",
    "        \"x\":0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "\n",
    "    candlestick.update_yaxes(title_text = 'Price in USD', ticksuffix = '$')\n",
    "    return candlestick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "btc_candle = c_chart(btc[-90:], label=\"BTC Price\")\n",
    "btc_candle.show()\n",
    "\n",
    "eth_candle = c_chart(eth[-90:], label=\"ETH Price \")\n",
    "eth_candle.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is used to emulate the env.iter_test()\n",
    "\n",
    "test_df = pd.read_csv('data/g-research-crypto-forecasting/example_test.csv')\n",
    "sub_df = pd.read_csv('data/g-research-crypto-forecasting/example_sample_submission.csv')\n",
    "sub_df['Target'] = sub_df.Target.astype(float)\n",
    "iter_test = [(test_df[test_df.group_num == g].reset_index(drop=True).drop(columns='group_num'), sub_df[sub_df.group_num == g].reset_index(drop=True).drop(columns='group_num')) for g in test_df.group_num.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data that is just before the test set\n",
    "sup = pd.read_csv('data/g-research-crypto-forecasting/supplemental_train.csv').sort_values(by=['timestamp', 'Asset_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the last 15 min are useful\n",
    "sup = sup[-WINDOW_SIZE * (N_ASSETS):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the sup data. Test data will be appended\n",
    "sup = feature_eng(sup)\n",
    "test_sample = np.array(sup[feature_cols])\n",
    "test_sample = test_sample.reshape(-1, (N_ASSETS), test_sample.shape[-1])\n",
    "test_sample = np.expand_dims(test_sample, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "env = gresearch_crypto.make_env()\n",
    "iter_test = env.iter_test()\n",
    "\"\"\"\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    # get the features\n",
    "    test_df = feature_eng(test_df)\n",
    "    \n",
    "    # always sort by time, then by Asset_ID\n",
    "    test_df = test_df.sort_values(by=['timestamp', 'Asset_ID'])\n",
    "    \n",
    "    # to map to the corresponding rows    \n",
    "    asset_id_row_id_map = {a_id: r_id for a_id, r_id in test_df[['Asset_ID', 'row_id']].values}\n",
    "    \n",
    "    # matrix of features\n",
    "    test = np.array(test_df[feature_cols].fillna(0))\n",
    "    \n",
    "    # reshaping (similar to the train)\n",
    "    test = test.reshape(-1, 1, N_ASSETS, test.shape[-1])\n",
    "    \n",
    "    # Stack the test data to previous data, keep only last 15 min \n",
    "    test_sample = np.hstack([test_sample, test])[:,-WINDOW_SIZE:]\n",
    "    \n",
    "    y_pred = model.predict(test_sample).squeeze().reshape(-1, 1).squeeze()\n",
    "    \n",
    "    for i, p in enumerate(y_pred):\n",
    "        sample_prediction_df.loc[sample_prediction_df['row_id'] == asset_id_row_id_map[i], 'Target'] = p\n",
    "    \"\"\"env.predict(sample_prediction_df)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
